#!/usr/bin/env python3
#
#Andrew Geiss, March 2022
#
#generates the training and validation sets used in the study. the numpy
#random seed is set below (to 123) to ensure the same validation split
#can be reproduced in the future. this script does not do any optics
#calculations. it simply loads the data in a pre-computed high-resolution optics
#table generated by 'create_optics_tables.py' and performs pre-processing and
#does a train/validation split

import numpy as np

def standardize(x,verbose=False):
    #standardizes the input matrix to a mean of zero and standard deviation of one
    mn = np.mean(x)
    std = np.std(x)
    if verbose:
        print('Mean=' + str(mn) + '   ' + 'STD=' + str(std))
    return (x-mn)/std

def rep_dims(x,counts):
    #repeats the input array along multiple axes (wrapper for numpy 'repeat') that
    #can handle multiple axes in one call
    for i in range(len(counts)):
        if x.shape[i]==1:
            x = np.repeat(x,counts[i],axis=i)
    return x

def one_hot(x):
    #converts an input vector of integer labels into a one-hot encoding
    x = np.uint8(x)
    x = np.stack([x==i for i in range(np.max(x)+1)],axis=1)
    return x

def create_input_data(dataset, shape, bands=None):
    ax = np.newaxis
    
    #the refractive indices:
    refr = dataset['ref_index_real']
    refi = dataset['ref_index_imag']
    if not bands is None:
        refr, refi = refr[bands,:], refi[bands,:]
    print('Standardizing real refractive index: ',end='')
    refr = standardize(refr,verbose=True)
    print('Standardizing imaginary refractive index: ',end='')
    refi = standardize(np.log(refi+1E-6),verbose=True)
    refr = rep_dims(refr[ax,:,:,ax,ax],shape)
    refi = rep_dims(refi[ax,:,ax,:,ax],shape)
    
    #the surface mode radius, wavelength, and size param:
    rs = rep_dims(dataset['surf_mode_radius'][ax,ax,ax,ax,:],shape)
    wavl = dataset['wavelengths']
    if not bands is None:
        wavl = wavl[bands]
    wavl = rep_dims(wavl[ax,:,ax,ax,ax],shape)
    rssp = rs/wavl
    print('Standardizing wavelength: ',end='')
    wavl = standardize(np.log(wavl),verbose=True)
    print('Standardizing rs/wavelength: ',end='')
    rssp = standardize(np.log(rssp),verbose=True)
    print('Standardizing rs: ',end='')
    rs = standardize(np.log(rs),verbose=True)
    
    #the aerosol modes:
    mode = rep_dims(np.arange(4)[:,ax,ax,ax,ax],shape).flatten()
    mode = one_hot(mode)
    
    #combine everything and convert to float16:
    inputs = np.stack([i.flatten() for i in [wavl, refr, refi, rssp, rs]],axis=1)
    inputs = np.float16(np.concatenate([inputs,mode],axis=1))
    
    return inputs

def save_training_data(inputs,targets,name):
    #break into training and testing components:
    np.random.seed(123)
    N = targets.shape[0]
    test_inds = np.random.choice(np.arange(N),N//2,replace=False)
    train_targets = targets[test_inds,...]
    test_targets  = np.delete(targets,test_inds,axis=0)
    train_inputs = inputs[test_inds,:]
    test_inputs  = np.delete(inputs,test_inds,axis=0)
    
    #save
    np.save('./data/training_data/' + name + '_targets_train.npy',train_targets)
    np.save('./data/training_data/' + name + '_targets_test.npy',test_targets)
    np.save('./data/training_data/' + name + '_inputs_train.npy',train_inputs)
    np.save('./data/training_data/' + name + '_inputs_test.npy',test_inputs)
    
def make_training_set():
    
    #load the sw data:
    data = np.load('./data/optics_tables/sw/129,129,2049,257.npz')
    
    #SW bands:
    print('SW----------------')
    scales = [2.2,4.6,1.0]
    optics = data['optics']
    inputs = create_input_data(data,optics.shape[1:])
    targets = np.array([optics[i,...].flatten().T/scales[i] for i in range(3)],dtype='float16').T
    save_training_data(inputs,targets,'sw')
    
    #load the LW data:
    data = np.load('./data/optics_tables/lw/129,129,2049,257.npz')
    
    #1st set of LW bands:
    print('LW1---------------')
    bands = [2,3,4,5,8,9,10,11,12,13,14,15]
    absp = np.float16(data['optics'][0,...]/2.2)
    targets = absp[:,bands,...]
    inputs = create_input_data(data,targets.shape,bands=bands)
    targets = targets.flatten()
    save_training_data(inputs,targets,'lw1')
    
    #2nd set of LW bands:
    print('LW2 --------------')
    bands = [0,1,6,7]
    targets = absp[:,bands,...]
    inputs = create_input_data(data,targets.shape,bands=bands)
    targets = targets.flatten()
    save_training_data(inputs,targets,'lw2')


if __name__ == '__main__':
    make_training_set()