#!/usr/bin/env python3
#
#Andrew Geiss, March 2022
#
#generates the training and validation sets used in the study. the numpy
#random seed is set below (to 123) to ensure the same validation split
#can be reproduced in the future. this script does not do any optics
#calculations. it simply loads the data in a pre-computed high-resolution optics
#table generated by 'create_optics_tables.py' and performs pre-processing and
#does a train/validation split

#input normalization:
stds =  {'lw':  {'wavelength':   1.1, 'refr': 0.3, 'refi':  3.9, 'rssp':  2.5, 'rs':   2.3},
         'sw':  {'wavelength':   1.0, 'refr': 0.2, 'refi':  4.0, 'rssp':  3.9, 'rs':   2.3}}
means = {'lw':  {'wavelength': -11.5, 'refr': 1.7, 'refi': -7.0, 'rssp': -3.0, 'rs': -14.5},
         'sw':  {'wavelength': -13.6, 'refr': 1.6, 'refi': -7.0, 'rssp': -0.9, 'rs': -14.5}}

#output scaling:
#lw & sw abs: 1.6
#sw ext: 3.4
#sw asym: 1.0

import numpy as np

def standardize(x,varname,wl_region):
    #standardizes the input matrix
    if not varname == 'refr':
        x = np.log(x)
    return np.float32((x-means[wl_region][varname])/stds[wl_region][varname])

def standardize_inv(x,varname,wl_region):
    #inverse of previous function
    x = np.double(x)
    x = x*stds[wl_region][varname]+means[wl_region][varname]
    if not varname == 'refr':
        x = np.exp(x)
    return x

def rep_dims(x,counts):
    #repeats the input array along multiple axes (wrapper for numpy 'repeat') that
    #can handle multiple axes in one call
    for i in range(len(counts)):
        if x.shape[i]==1:
            x = np.repeat(x,counts[i],axis=i)
    return x

def one_hot(x):
    #converts an input vector of integer labels into a one-hot encoding
    x = np.uint8(x)
    x = np.stack([x==i for i in range(np.max(x)+1)],axis=1)
    return np.float32(x)

def create_input_data(dataset, shape, wl_region):
    ax = np.newaxis
    
    #the refractive indices:
    refr = dataset['ref_index_real']
    refi = dataset['ref_index_imag']
    refr = standardize(refr,'refr', wl_region)
    refi = standardize(refi+1E-6,'refi', wl_region)
    refr = rep_dims(refr[ax,:,:,ax,ax],shape)
    refi = rep_dims(refi[ax,:,ax,:,ax],shape)
    
    #the surface mode radius, wavelength, and size param:
    rs = rep_dims(dataset['surf_mode_radius'][ax,ax,ax,ax,:],shape)
    wavl = dataset['wavelengths']
    wavl = rep_dims(wavl[ax,:,ax,ax,ax],shape)
    rssp = rs/wavl
    wavl = standardize(wavl,'wavelength', wl_region)
    rssp = standardize(rssp,'rssp', wl_region)
    rs = standardize(rs,'rs', wl_region)
    
    #the aerosol modes:
    mode = rep_dims(np.arange(4)[:,ax,ax,ax,ax],shape).flatten()
    mode = one_hot(mode)
    
    #combine everything into one matrix:
    inputs = np.stack([inp_var.flatten() for inp_var in [wavl, refr, refi, rssp, rs]],axis=1)
    inputs = np.concatenate([inputs,mode],axis=1)
    
    return inputs

def save_training_data(inputs,targets,name):
    #break into training and testing components:
    np.random.seed(123)
    N = targets.shape[0]
    test_inds = np.random.choice(np.arange(N),N//2,replace=False)
    train_targets = targets[test_inds,...]
    test_targets  = np.delete(targets,test_inds,axis=0)
    train_inputs = inputs[test_inds,:]
    test_inputs  = np.delete(inputs,test_inds,axis=0)
    
    #save
    np.save('./data/training/' + name + '_targets.npy',train_targets)
    np.save('./data/validation/' + name + '_targets.npy',test_targets)
    np.save('./data/training/' + name + '_inputs.npy',train_inputs)
    np.save('./data/validation/' + name + '_inputs.npy',test_inputs)
    
def make_training_set():
    
    #load the sw data:
    data = np.load('./data/optics_tables/sw/129,129,2049,257.npz')
    scales = np.array([1.6,3.4,1.0])
    optics = data['optics']
    inputs = create_input_data(data,optics.shape[1:],'sw')
    targets = np.array([np.float32(optics[i,...].flatten().T/scales[i]) for i in range(3)]).T
    save_training_data(inputs,targets,'sw')
    
    #load the LW data:
    data = np.load('./data/optics_tables/lw/129,129,2049,257.npz')
    absp = np.float32(data['optics'][0,...]/1.6)
    targets = absp.flatten()
    inputs = create_input_data(data,absp.shape,'lw')
    save_training_data(inputs,targets,'lw')

if __name__ == '__main__':
    make_training_set()